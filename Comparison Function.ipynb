{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3e2fda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import path\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007853a8",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "34473e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = r\"C:\\Users\\Fahad Razzaq\\Desktop\\Fahad data\\All Results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6bf9a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "\n",
    "def create_directory():\n",
    "    \"\"\"\n",
    "    Creates a directory on the desktop with the name \"results_YYYYMMDD\", \n",
    "    where YYYY is the current year, MM is the current month, \n",
    "    and DD is the current day.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get today's date and store it in a variable called today\n",
    "    today = date.today()\n",
    "    \n",
    "    # Create a string called directory using the strftime method of the today object, which formats the date in the format \"results_YYYYMMDD\"\n",
    "    directory = today.strftime(\"results_%Y%m%d\")  ## folder name\n",
    "    \n",
    "    # Set the value of the parent_dir variable to the path of the All Results folder on the desktop, with a \"\\\" character appended at the end\n",
    "    parent_dir = results_path + '\\\\' \n",
    "    \n",
    "    # Use the os.path.join function to combine the parent_dir and directory variables into the target_path\n",
    "    target_path = os.path.join(parent_dir, directory)\n",
    "    \n",
    "    # Create a directory at the target_path location with the name specified in the directory variable\n",
    "    os.mkdir(target_path)\n",
    "    return directory\n",
    "\n",
    "### Call this funtion only once a day\n",
    "directory = create_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "98ca6423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison(df1, df2, merge_on, col):\n",
    "    \"\"\"\n",
    "    Compares two dataframes and returns a summary of their differences and detailed information about the differences.\n",
    "    \n",
    "    Parameters:\n",
    "        df1 (pandas dataframe): The first dataframe to compare.\n",
    "        df2 (pandas dataframe): The second dataframe to compare.\n",
    "        merge_on (str or list): The column(s) to merge the dataframes on.\n",
    "        col (str): The column to compare for changes.\n",
    "        \n",
    "    Returns:\n",
    "        Fcount (pandas dataframe): A dataframe containing the count of differences in each category.\n",
    "        detail (pandas dataframe): A dataframe containing detailed information about the differences.\n",
    "    \"\"\"\n",
    "    # Initializes delta to 0.1\n",
    "    delta=0.1\n",
    "        \n",
    "    # Prints the number of rows in df1 and df2\n",
    "    print('NEW  Entries     : ',len(df1))\n",
    "    print('OLD  Entries     : ',len(df2))\n",
    "\n",
    "    # Merges df1 and df2 on the merge_on column and adds '_new' and '_old' suffixes to the merged dataframe columns\n",
    "    comp = df1.merge(right=df2, how='outer', on= merge_on, suffixes=('_new', '_old'))\n",
    "    # Initializes a new 'Category' column in comp to be NA\n",
    "    comp['Category'] = pd.NA\n",
    "    # If the difference between the 'col' column in df1 and 'col' column in df2 is greater than delta, the 'Category' column is updated to 'Price Increased'\n",
    "    comp.loc[comp[col + '_new'] - comp[col + '_old'] > delta , 'Category'] = 'Price Increased'\n",
    "    # If the difference between the 'col' column in df2 and 'col' column in df1 is greater than delta, the 'Category' column is updated to 'Price Decreased'\n",
    "    comp.loc[comp[col + '_old'] - comp[col + '_new'] > delta, 'Category'] = 'Price Decreased'\n",
    "    # If the absolute difference between the 'col' column in df1 and 'col' column in df2 is less than or equal to delta, the 'Category' column is updated to 'Same Price'\n",
    "    comp.loc[abs(comp[col + '_new'] - comp[col + '_old']) <= delta, 'Category'] = 'Same Price'\n",
    "    # If the 'col' column in df1 is not NA and the 'col' column in df2 is NA, the 'Category' column is updated to 'Items Added'\n",
    "    comp.loc[(~comp[col + '_new'].isna()) & (comp[col + '_old'].isna()), 'Category'] = 'Items Added'\n",
    "    # If the 'col' column in df2 is not NA and the 'col' column in df1 is NA, the 'Category' column is updated to 'Items Removed'\n",
    "    comp.loc[(comp[col + '_new'].isna()) & (~comp[col + '_old'].isna()), 'Category'] = 'Items Removed'\n",
    "\n",
    "    # Prints the number of rows where the difference between the 'col' column in df1 and 'col' column in df2 is greater than delta\n",
    "    print('Increase in Price: ', len(comp[comp[col + '_new'] > (comp[col + '_old'] +  delta)]))\n",
    "    # Prints the number of rows where the difference between the 'col' column in df1 and 'col' column in df2 is less than delta\n",
    "    print('Decrease in Price: ', len(comp[comp[col + '_new'] < (comp[col + '_old'] -  delta)]))\n",
    "    # Prints the number of rows where the absolute difference between the 'col' column in df1 and 'col' column in df2 is less than or equal to delta\n",
    "    print('Same Price       : ', len(comp[abs(comp[col + '_new'] - comp[col + '_old']) <=  delta]))\n",
    "    # Prints the number of rows where the 'col' column in df1 is not NA and the 'col' column in df2 is NA\n",
    "    print('Increase in Parts: ', len(comp[(~comp[col + '_new'].isna()) & (comp[col + '_old'].isna())]))\n",
    "    # Prints the number of rows where the 'col' column in df2 is not NA and the 'col' column in df1 is NA\n",
    "    print('Decrease in Parts: ', len(comp[(comp[col + '_new'].isna()) & (~comp[col + '_old'].isna())]))\n",
    "    \n",
    "    # Selects all rows in comp where the 'Category' column is not 'Same Price' and stores the result in 'detail\n",
    "    detail = comp.loc[comp['Category'] != 'Same Price']\n",
    "    \n",
    "    # Groups the rows in comp by the 'Category' column\n",
    "    group = comp.groupby('Category')\n",
    "    \n",
    "    # Selects the 'Category' column of the grouped dataframe get the count of each label in category column\n",
    "    Fcount = group[['Category']].count()\n",
    "    \n",
    "    # Renames the 'Category' column to 'Count'\n",
    "    Fcount.rename(columns={'Category': 'Count'}, inplace=True)\n",
    "    \n",
    "    #Resets the index of Fcount\n",
    "    Fcount.reset_index(inplace=True)\n",
    "    \n",
    "    # Returns Fcount and detail\n",
    "    return Fcount, detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187e791d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ed55c",
   "metadata": {},
   "source": [
    "# Date Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d02165bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dateextract(f):\n",
    "        \n",
    "    \"\"\"\n",
    "    Extracts the date from a file name and returns it as a date object.\n",
    "    \n",
    "    Parameters:\n",
    "    f (string): The file name to extract the date from.\n",
    "    \n",
    "    Returns:\n",
    "    datetime.date: The date extracted from the file name.\n",
    "    \n",
    "    \"\"\"\n",
    "    #get the base name of the file (i.e., the file name without the path)\n",
    "    b= path.basename(f)\n",
    "\n",
    "    #split the base name by '.' and take the first element (the part before the first '.'). Then, split this by '_' and take the second element (the part after the first '_')\n",
    "    c= b.split('.')[0].split('_')[1]\n",
    "\n",
    "    #convert the string to a datetime object and return just the date part\n",
    "    d = datetime.datetime.strptime(c, \"%Y%m%d\").date()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc39c9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f83b7e0",
   "metadata": {},
   "source": [
    "# Read File and Add Date Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5cd5f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(f, sep=',', encoding=None, encoding_errors='strict', escapechar=None, on_bad_lines='warn'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read a CSV file into a pandas DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    f: path to file to be read\n",
    "    sep: character to use as separator\n",
    "    encoding: encoding to use when reading the file\n",
    "    encoding_errors: how to handle encoding errors\n",
    "    escapechar: character to use to escape special characters\n",
    "    on_bad_lines: how to handle bad lines\n",
    "    \n",
    "    Returns:\n",
    "    A pandas DataFrame with an additional 'Date' column added    \n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(f,sep=sep, encoding=encoding, encoding_errors=encoding_errors, escapechar=escapechar, on_bad_lines=on_bad_lines)\n",
    "    # Extract the date from the file name\n",
    "    dt = dateextract(f)\n",
    "    # Add the date to the DataFrame as a column\n",
    "    df['Date'] = dt\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73e0336",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e8902f",
   "metadata": {},
   "source": [
    "# Protocols for each warehouse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f687c9",
   "metadata": {},
   "source": [
    "### Brock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bb2f0962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  11520\n",
      "OLD  Entries     :  11518\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  11518\n",
      "Increase in Parts:  2\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "# import the pathlib module\n",
    "import pathlib\n",
    "\n",
    "# assign a variable desktop to a Path object representing the specified directory\n",
    "desktop = pathlib.Path(r\"C:\\Users\\Fahad Razzaq\\Desktop\\Fahad data\\Daily comparison\")\n",
    "\n",
    "# assign the variable latest_date to the last file in the desktop directory with a name starting with \"brock\"\n",
    "latest_date = list(desktop.rglob(\"brock*\"))[-1]\n",
    "# assign the variable previous_date to the second to last file in the desktop directory with a name starting with \"brock\"\n",
    "previous_date = list(desktop.rglob(\"brock*\"))[-2]\n",
    "\n",
    "# read in the data from the latest date file\n",
    "df1= read_df(latest_date)\n",
    "# read in the data from the previous date file\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "# specify the column to merge the dataframes on\n",
    "merge_on= ['sku']\n",
    "# specify the column to compare\n",
    "col='prices'\n",
    "\n",
    "# perform the comparison and store the results in variables a and b\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "\n",
    "# add additional information to the a dataframe\n",
    "a['Warehouse']= 'BROCK'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "# save the a dataframe to an Excel file\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"brock_Summary.xlsx\", index = False)\n",
    "# save the b dataframe to an Excel file\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"brock_Detail.xlsx\")\n",
    "\n",
    "# store the a dataframe in a list\n",
    "result=[a]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365cc960",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927e9be8",
   "metadata": {},
   "source": [
    "### Burco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0f1abc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  4312\n",
      "OLD  Entries     :  4312\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  4314\n",
      "Increase in Parts:  0\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"burco*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"burco*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "merge_on= ['vendor_sku']\n",
    "col='Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'BURCO'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"burco_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"burco_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c856408",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695ffc2",
   "metadata": {},
   "source": [
    "### Jante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "432fd1e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13616\\1623257769.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprevious_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesktop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"jante*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatest_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmerge_on\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'LC'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'vendor_sku'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13616\\22380274.py\u001b[0m in \u001b[0;36mread_df\u001b[1;34m(f, sep, encoding, encoding_errors, escapechar, on_bad_lines)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \"\"\"\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_bad_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Extract the date from the file name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdateextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"jante*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"jante*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "merge_on= ['LC' , 'vendor_sku']\n",
    "col='Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'JANTE'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"jante_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"jante_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0055b2d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58533e8a",
   "metadata": {},
   "source": [
    "### Keystone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "b7b0f985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  146720\n",
      "OLD  Entries     :  146518\n",
      "Increase in Price:  374\n",
      "Decrease in Price:  4\n",
      "Same Price       :  145829\n",
      "Increase in Parts:  511\n",
      "Decrease in Parts:  309\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"keystone*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"keystone*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['VCPN']\n",
    "col='Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'KEYSTONE'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"Keystone_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"Keystone_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b974029",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e8842",
   "metadata": {},
   "source": [
    "### Motorstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "eab4a095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  104950\n",
      "OLD  Entries     :  104929\n",
      "Increase in Price:  403\n",
      "Decrease in Price:  35\n",
      "Same Price       :  104484\n",
      "Increase in Parts:  28\n",
      "Decrease in Parts:  7\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"motorstate*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"motorstate*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['Brand' , 'PartNumber']\n",
    "col='Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'MOTORSTATE'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"motorstate_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"motorstate_Detail.xlsx\", index = False)\n",
    "\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2007e47",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ba1ee",
   "metadata": {},
   "source": [
    "### NPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2ebaf573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  293573\n",
      "OLD  Entries     :  293653\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  293532\n",
      "Increase in Parts:  41\n",
      "Decrease in Parts:  121\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"npw*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"npw*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['LineCode' , 'PartN']\n",
    "col='Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'NPW'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"npw_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"npw_Detail.xlsx\", index = False)\n",
    "\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38a802",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e55ca4c",
   "metadata": {},
   "source": [
    "### PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "22a07fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  533767\n",
      "OLD  Entries     :  533984\n",
      "Increase in Price:  660\n",
      "Decrease in Price:  1260\n",
      "Same Price       :  529519\n",
      "Increase in Parts:  2326\n",
      "Decrease in Parts:  2543\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"pa*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"pa*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date, encoding='unicode_escape')\n",
    "df2=read_df(previous_date, encoding='unicode_escape')\n",
    "\n",
    "merge_on= ['Line' , 'Part']\n",
    "col='Price'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'PA'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"PA_summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"pa_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a454074",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b48895b",
   "metadata": {},
   "source": [
    "### PFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e76ddbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  88515\n",
      "OLD  Entries     :  88522\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  88511\n",
      "Increase in Parts:  4\n",
      "Decrease in Parts:  11\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"pfg*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"pfg*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date, sep='\\t', escapechar = '\\\\', encoding_errors='ignore')\n",
    "df2=read_df(previous_date, sep='\\t', escapechar = '\\\\', encoding_errors='ignore')\n",
    "\n",
    "merge_on = ['SKU', 'BRAND']\n",
    "col='COST'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'PFG'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"pfg_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"pfg_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44052b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8c318",
   "metadata": {},
   "source": [
    "### RSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "2c24e378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  5622\n",
      "OLD  Entries     :  5622\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  5623\n",
      "Increase in Parts:  0\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"rsl*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"rsl*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['SKU', 'Brand']\n",
    "col='BSAP Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'RSL'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"rsl_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"rsl_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11350f9d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b91d1",
   "metadata": {},
   "source": [
    "### Sunbelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e563e2a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  1580\n",
      "OLD  Entries     :  1580\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  1580\n",
      "Increase in Parts:  0\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"sunbelt*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"sunbelt*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['SKU']\n",
    "col='Price'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'SUNBELT'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"unbelt_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"sunbelt_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3c54b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdd192",
   "metadata": {},
   "source": [
    "### Simple Tire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "afcaaff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  44868\n",
      "OLD  Entries     :  44890\n",
      "Increase in Price:  5453\n",
      "Decrease in Price:  39014\n",
      "Same Price       :  219\n",
      "Increase in Parts:  181\n",
      "Decrease in Parts:  203\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"simpletire*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"simpletire*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['Product ID']\n",
    "col='Price'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'SIMPLE TIRE'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"simpletire_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"simpletire_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e974a2",
   "metadata": {},
   "source": [
    "## Keystone Crash - LKQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2bcf2b80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 20402: expected 34 fields, saw 35\\nSkipping line 29364: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 34071: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 20389: expected 34 fields, saw 35\\nSkipping line 29350: expected 34 fields, saw 35\\n'\n",
      "b'Skipping line 34053: expected 34 fields, saw 35\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  76665\n",
      "OLD  Entries     :  76637\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  76447\n",
      "Increase in Parts:  218\n",
      "Decrease in Parts:  190\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"lkq*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"lkq*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['PartNumber']\n",
    "col='CustomerPrice'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'LKQ'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"LKQ_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"LKQ_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae57ca9c",
   "metadata": {},
   "source": [
    "### Dorman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3e637125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  81759\n",
      "OLD  Entries     :  81753\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  81753\n",
      "Increase in Parts:  6\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"dorman*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"dorman*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "df1['Price']=  0\n",
    "df2['Price']=  0\n",
    "\n",
    "\n",
    "df1.columns = ['599-403', 'Call For Availability', '2023-02-01 16:28:14', 'Unnamed: 3',\n",
    "       'Unnamed: 4', 'Unnamed: 5', 'Date', 'Price']\n",
    "df2.columns = ['599-403', 'Call For Availability', '2023-02-01 16:28:14', 'Unnamed: 3',\n",
    "       'Unnamed: 4', 'Unnamed: 5', 'Date', 'Price']\n",
    "\n",
    "merge_on= ['599-403']\n",
    "\n",
    "col= 'Price'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'DORMAN'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"dorman_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"dorman_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c11b1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62010dc",
   "metadata": {},
   "source": [
    "### OE Wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7100aefc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  769\n",
      "OLD  Entries     :  766\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  766\n",
      "Increase in Parts:  3\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"oe*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"oe*\"))[-2]\n",
    "\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['UPC']\n",
    "\n",
    "df1['Price']=  0\n",
    "df2['Price']=  0\n",
    "col= 'Price'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'OE WHEELS'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"oe_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"oe_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414a14da",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3315244",
   "metadata": {},
   "source": [
    "### Tonsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "37b3b1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahad Razzaq\\AppData\\Local\\Temp\\ipykernel_13616\\22380274.py:18: DtypeWarning: Columns (3,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f,sep=sep, encoding=encoding, encoding_errors=encoding_errors, escapechar=escapechar, on_bad_lines=on_bad_lines)\n",
      "C:\\Users\\Fahad Razzaq\\AppData\\Local\\Temp\\ipykernel_13616\\22380274.py:18: DtypeWarning: Columns (3,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f,sep=sep, encoding=encoding, encoding_errors=encoding_errors, escapechar=escapechar, on_bad_lines=on_bad_lines)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  48335\n",
      "OLD  Entries     :  48197\n",
      "Increase in Price:  4\n",
      "Decrease in Price:  1\n",
      "Same Price       :  48016\n",
      "Increase in Parts:  316\n",
      "Decrease in Parts:  178\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"tonsa*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"tonsa*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['Tonsa#']\n",
    "df1['Price']=  df1['Core'] + df1['Cost']\n",
    "df2['Price']=  df2['Core'] + df2['Cost']\n",
    "col= 'Price'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'Tonsa'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"Tonsa_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"Tonsa_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ba008",
   "metadata": {},
   "source": [
    "### Wheel Pros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "03bc7de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  64315\n",
      "OLD  Entries     :  64315\n",
      "Increase in Price:  0\n",
      "Decrease in Price:  0\n",
      "Same Price       :  64315\n",
      "Increase in Parts:  0\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"wp*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"wp*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['LC', 'PartNumber']\n",
    "col='cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'Wheel Pros'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"WP_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"WP_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20545b3",
   "metadata": {},
   "source": [
    "### Turn 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3dc7cdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  343825\n",
      "OLD  Entries     :  344190\n",
      "Increase in Price:  2\n",
      "Decrease in Price:  0\n",
      "Same Price       :  343819\n",
      "Increase in Parts:  4\n",
      "Decrease in Parts:  369\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"t14*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"t14*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "df1.columns.values[0] = 'sku_filtered'\n",
    "df2.columns.values[0] = 'sku_filtered'\n",
    "merge_on= ['sku_filtered']\n",
    "col='Cost'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'Turn 14'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    "\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"T14_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"T14_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5a1bd0",
   "metadata": {},
   "source": [
    "### RRW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1e1fe5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW  Entries     :  3155\n",
      "OLD  Entries     :  3042\n",
      "Increase in Price:  53\n",
      "Decrease in Price:  1\n",
      "Same Price       :  3045\n",
      "Increase in Parts:  112\n",
      "Decrease in Parts:  0\n"
     ]
    }
   ],
   "source": [
    "latest_date = list(desktop.rglob(\"RRW*\"))[-1]\n",
    "previous_date = list(desktop.rglob(\"RRW*\"))[-2]\n",
    "\n",
    "df1=read_df(latest_date)\n",
    "df2=read_df(previous_date)\n",
    "\n",
    "merge_on= ['SKU']\n",
    "\n",
    "col= 'MAP'\n",
    "\n",
    "a,b = comparison(df1, df2, merge_on, col)\n",
    "a['Warehouse']= 'RRW'\n",
    "a['Latest Date']= df1.loc[0, 'Date']\n",
    "a['Previous Date']= df2.loc[0, 'Date']\n",
    ", index = False\n",
    "a.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"RRW_Summary.xlsx\", index = False)\n",
    "b.to_excel(results_path  + \"\\\\\" + directory + \"\\\\\" + \"RRW_Detail.xlsx\", index = False)\n",
    "result.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a3bea",
   "metadata": {},
   "source": [
    "#### Zip all summary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "189ab56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brock_Detail.xlsx',\n",
       " 'brock_Summary.xlsx',\n",
       " 'burco_Detail.xlsx',\n",
       " 'burco_Summary.xlsx',\n",
       " 'dorman_Detail.xlsx',\n",
       " 'dorman_Summary.xlsx',\n",
       " 'Keystone_Detail.xlsx',\n",
       " 'Keystone_Summary.xlsx',\n",
       " 'LKQ_Detail.xlsx',\n",
       " 'LKQ_Summary.xlsx',\n",
       " 'motorstate_Detail.xlsx',\n",
       " 'motorstate_Summary.xlsx',\n",
       " 'npw_Detail.xlsx',\n",
       " 'npw_Summary.xlsx',\n",
       " 'oe_Detail.xlsx',\n",
       " 'oe_Summary.xlsx',\n",
       " 'pa_Detail.xlsx',\n",
       " 'PA_summary.xlsx',\n",
       " 'pfg_Detail.xlsx',\n",
       " 'pfg_Summary.xlsx',\n",
       " 'RRW_Detail.xlsx',\n",
       " 'RRW_Summary.xlsx',\n",
       " 'rsl_Detail.xlsx',\n",
       " 'rsl_Summary.xlsx',\n",
       " 'simpletire_Detail.xlsx',\n",
       " 'simpletire_Summary.xlsx',\n",
       " 'sunbelt_Detail.xlsx',\n",
       " 'T14_Detail.xlsx',\n",
       " 'T14_Summary.xlsx',\n",
       " 'Tonsa_Detail.xlsx',\n",
       " 'Tonsa_Summary.xlsx',\n",
       " 'unbelt_Summary.xlsx',\n",
       " 'WP_Detail.xlsx',\n",
       " 'WP_Summary.xlsx']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = results_path  + \"\\\\\" + directory\n",
    "files = os.listdir(folder)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2b96dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summary_20230106'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = date.today().strftime(\"summary_%Y%m%d\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8c6678c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the zipfile and fnmatch modules\n",
    "import zipfile\n",
    "import fnmatch\n",
    "from os.path import basename\n",
    "\n",
    "# create the file path for the zip file to be saved on the local machine\n",
    "zip_filename = results_path  + \"\\\\\" +  directory  + \"\\\\\" +  summary  +\".zip\"\n",
    "\n",
    "# open the zip file for writing\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "    # for each file in the list 'files' that has the extension \".xlsx\", do the following:\n",
    "    for file in fnmatch.filter(files, \"*.xlsx\"):\n",
    "        # create the file path for the current file by joining the file name with the 'folder' path\n",
    "        file_path = os.path.join(folder, file)\n",
    "        # add the current file to the zip file\n",
    "        zip_file.write(file_path, basename(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821a923",
   "metadata": {},
   "source": [
    "#### Send Files to Slack Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d9e066cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahad Razzaq\\anaconda3\\lib\\site-packages\\slack_sdk\\web\\client.py:3032: UserWarning: Although the channels parameter is still supported for smooth migration from legacy files.upload, we recommend using the new channel parameter with a single str value instead for more clarity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File sent to channel successfully!'"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the slack_sdk module\n",
    "import slack_sdk\n",
    "from datetime import date\n",
    "\n",
    "current_date = date.today()\n",
    "\n",
    "def send_update_to_slack_channel(text, file, channelid):\n",
    "    \n",
    "    \"\"\"Sends an update message and file to the specified Slack channel.\n",
    "\n",
    "    Args:\n",
    "    text : The text of the message to be sent.\n",
    "    file : The file to be sent (e.g. \"df_styled.png\").\n",
    "    channelid : The ID of the Slack channel to send the message and file to.\n",
    "\n",
    "    Returns:\n",
    "    str: A string indicating that the file was sent to the channel successfully.\n",
    "    \n",
    "    \"\"\"\n",
    "    # store the channel id for the slack channel where the message and file will be sent\n",
    "    cid = channelid\n",
    "\n",
    "    # create a client for the slack API using the WebClient class and the specified token\n",
    "    c = slack_sdk.WebClient(token='xoxb-156915382752-4437979958069-2XlrUKvulSUOltDeqdlHrqjA')\n",
    "\n",
    "    # create the text for the message to be sent, using the current date\n",
    "    text = text\n",
    "\n",
    "    # send a message to the specified slack channel with the created text\n",
    "    c.chat_postMessage(channel=cid, text=text)\n",
    "\n",
    "    # send the image file \"df_styled.png\" to the specified slack channel\n",
    "    \n",
    "    c.files_upload_v2(file=file, channels=cid)    \n",
    "    \n",
    "    return \"File sent to channel successfully!\"\n",
    "\n",
    "slack_text = 'Warehouse Summaries ' + current_date.strftime(\"%d-%m-%Y\")\n",
    "send_update_to_slack_channel(slack_text, zip_filename, \"C04D1HF1RHT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4f3f1",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e40955",
   "metadata": {},
   "source": [
    "# Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "dae7e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get current date for filename\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "today = date.today()\n",
    "filename = today.strftime(\"Inventory Summary_%Y%m%d.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "50918772",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = today\n",
    "yesterday_date = (today - timedelta(days = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac201f1e",
   "metadata": {},
   "source": [
    "#### Summary Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_path = r\"C:\\Users\\Fahad Razzaq\\Desktop\\Fahad data\\Summaries Excel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f5c640b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Count</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Latest Date</th>\n",
       "      <th>Previous Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>2</td>\n",
       "      <td>BROCK</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>2022-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>11518</td>\n",
       "      <td>BROCK</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>2022-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>4314</td>\n",
       "      <td>BURCO</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>511</td>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>309</td>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Price Decreased</td>\n",
       "      <td>4</td>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>376</td>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>145829</td>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>28</td>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>7</td>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Price Decreased</td>\n",
       "      <td>35</td>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>403</td>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>104484</td>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>41</td>\n",
       "      <td>NPW</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>121</td>\n",
       "      <td>NPW</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>293532</td>\n",
       "      <td>NPW</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>2326</td>\n",
       "      <td>PA</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>2543</td>\n",
       "      <td>PA</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Price Decreased</td>\n",
       "      <td>1260</td>\n",
       "      <td>PA</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>662</td>\n",
       "      <td>PA</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>529519</td>\n",
       "      <td>PA</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>4</td>\n",
       "      <td>PFG</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>11</td>\n",
       "      <td>PFG</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>88511</td>\n",
       "      <td>PFG</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>5623</td>\n",
       "      <td>RSL</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>1580</td>\n",
       "      <td>SUNBELT</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>2022-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>181</td>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>203</td>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Price Decreased</td>\n",
       "      <td>39014</td>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>5454</td>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>219</td>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>218</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>190</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>76447</td>\n",
       "      <td>LKQ</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>6</td>\n",
       "      <td>DORMAN</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>81753</td>\n",
       "      <td>DORMAN</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>3</td>\n",
       "      <td>OE WHEELS</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>766</td>\n",
       "      <td>OE WHEELS</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>316</td>\n",
       "      <td>Tonsa</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>178</td>\n",
       "      <td>Tonsa</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Price Decreased</td>\n",
       "      <td>1</td>\n",
       "      <td>Tonsa</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>4</td>\n",
       "      <td>Tonsa</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>48016</td>\n",
       "      <td>Tonsa</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>64315</td>\n",
       "      <td>Wheel Pros</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>4</td>\n",
       "      <td>Turn 14</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Items Removed</td>\n",
       "      <td>369</td>\n",
       "      <td>Turn 14</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>2</td>\n",
       "      <td>Turn 14</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>343819</td>\n",
       "      <td>Turn 14</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Items Added</td>\n",
       "      <td>112</td>\n",
       "      <td>RRW</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Price Decreased</td>\n",
       "      <td>1</td>\n",
       "      <td>RRW</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Price Increased</td>\n",
       "      <td>53</td>\n",
       "      <td>RRW</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Same Price</td>\n",
       "      <td>3045</td>\n",
       "      <td>RRW</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2023-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category   Count    Warehouse Latest Date Previous Date\n",
       "0       Items Added       2        BROCK  2022-10-12    2022-10-11\n",
       "1        Same Price   11518        BROCK  2022-10-12    2022-10-11\n",
       "2        Same Price    4314        BURCO  2023-01-06    2023-01-05\n",
       "3       Items Added     511     KEYSTONE  2023-01-06    2023-01-05\n",
       "4     Items Removed     309     KEYSTONE  2023-01-06    2023-01-05\n",
       "5   Price Decreased       4     KEYSTONE  2023-01-06    2023-01-05\n",
       "6   Price Increased     376     KEYSTONE  2023-01-06    2023-01-05\n",
       "7        Same Price  145829     KEYSTONE  2023-01-06    2023-01-05\n",
       "8       Items Added      28   MOTORSTATE  2023-01-05    2023-01-04\n",
       "9     Items Removed       7   MOTORSTATE  2023-01-05    2023-01-04\n",
       "10  Price Decreased      35   MOTORSTATE  2023-01-05    2023-01-04\n",
       "11  Price Increased     403   MOTORSTATE  2023-01-05    2023-01-04\n",
       "12       Same Price  104484   MOTORSTATE  2023-01-05    2023-01-04\n",
       "13      Items Added      41          NPW  2023-01-05    2023-01-04\n",
       "14    Items Removed     121          NPW  2023-01-05    2023-01-04\n",
       "15       Same Price  293532          NPW  2023-01-05    2023-01-04\n",
       "16      Items Added    2326           PA  2023-01-06    2023-01-05\n",
       "17    Items Removed    2543           PA  2023-01-06    2023-01-05\n",
       "18  Price Decreased    1260           PA  2023-01-06    2023-01-05\n",
       "19  Price Increased     662           PA  2023-01-06    2023-01-05\n",
       "20       Same Price  529519           PA  2023-01-06    2023-01-05\n",
       "21      Items Added       4          PFG  2023-01-06    2023-01-05\n",
       "22    Items Removed      11          PFG  2023-01-06    2023-01-05\n",
       "23       Same Price   88511          PFG  2023-01-06    2023-01-05\n",
       "24       Same Price    5623          RSL  2023-01-05    2023-01-04\n",
       "25       Same Price    1580      SUNBELT  2022-12-08    2022-12-07\n",
       "26      Items Added     181  SIMPLE TIRE  2023-01-05    2023-01-04\n",
       "27    Items Removed     203  SIMPLE TIRE  2023-01-05    2023-01-04\n",
       "28  Price Decreased   39014  SIMPLE TIRE  2023-01-05    2023-01-04\n",
       "29  Price Increased    5454  SIMPLE TIRE  2023-01-05    2023-01-04\n",
       "30       Same Price     219  SIMPLE TIRE  2023-01-05    2023-01-04\n",
       "31      Items Added     218          LKQ  2023-01-05    2023-01-04\n",
       "32    Items Removed     190          LKQ  2023-01-05    2023-01-04\n",
       "33       Same Price   76447          LKQ  2023-01-05    2023-01-04\n",
       "34      Items Added       6       DORMAN  2023-01-05    2023-01-04\n",
       "35       Same Price   81753       DORMAN  2023-01-05    2023-01-04\n",
       "36      Items Added       3    OE WHEELS  2023-01-05    2023-01-04\n",
       "37       Same Price     766    OE WHEELS  2023-01-05    2023-01-04\n",
       "38      Items Added     316        Tonsa  2023-01-05    2023-01-04\n",
       "39    Items Removed     178        Tonsa  2023-01-05    2023-01-04\n",
       "40  Price Decreased       1        Tonsa  2023-01-05    2023-01-04\n",
       "41  Price Increased       4        Tonsa  2023-01-05    2023-01-04\n",
       "42       Same Price   48016        Tonsa  2023-01-05    2023-01-04\n",
       "43       Same Price   64315   Wheel Pros  2023-01-05    2023-01-04\n",
       "44      Items Added       4      Turn 14  2023-01-06    2023-01-04\n",
       "45    Items Removed     369      Turn 14  2023-01-06    2023-01-04\n",
       "46  Price Increased       2      Turn 14  2023-01-06    2023-01-04\n",
       "47       Same Price  343819      Turn 14  2023-01-06    2023-01-04\n",
       "48      Items Added     112          RRW  2023-01-06    2023-01-04\n",
       "49  Price Decreased       1          RRW  2023-01-06    2023-01-04\n",
       "50  Price Increased      53          RRW  2023-01-06    2023-01-04\n",
       "51       Same Price    3045          RRW  2023-01-06    2023-01-04"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# concatenate the list of dataframes 'result' into a single dataframe 'r', ignoring the original indices\n",
    "r = pd.concat(result, ignore_index=True)\n",
    "\n",
    "# create the file path for saving the concatenated dataframe 'r' on the local machine\n",
    "summary_path =summary_path + '\\\\' + filename\n",
    "\n",
    "# save the 'r' dataframe to an excel file at the specified file path\n",
    "r.to_excel(summary_path, index=False)\n",
    "\n",
    "# display the 'r' dataframe\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "2beec215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahad Razzaq\\anaconda3\\lib\\site-packages\\slack_sdk\\web\\client.py:3032: UserWarning: Although the channels parameter is still supported for smooth migration from legacy files.upload, we recommend using the new channel parameter with a single str value instead for more clarity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<slack_sdk.web.slack_response.SlackResponse at 0x2045a4148b0>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the slack_sdk module\n",
    "import slack_sdk\n",
    "from datetime import date\n",
    "\n",
    "current_date = date.today()\n",
    "\n",
    "slack_text = 'Inventory Summary: ' + current_date.strftime(\"%d-%m-%Y\")\n",
    "send_update_to_slack_channel(slack_text, summary_path, \"C04D1HF1RHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9761a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_update = r\"C:\\Users\\Fahad Razzaq\\Desktop\\Fahad data\\Summaries Update\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1864d5be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Previous Date</th>\n",
       "      <th>Latest Date</th>\n",
       "      <th>Same Price</th>\n",
       "      <th>Items Added</th>\n",
       "      <th>Items Removed</th>\n",
       "      <th>Price Decreased</th>\n",
       "      <th>Price Increased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROCK</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>2022-10-12</td>\n",
       "      <td>11518.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURCO</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>4314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DORMAN</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>81753.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>145829.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LKQ</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>76447.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>104484.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NPW</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>293532.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OE WHEELS</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>766.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PA</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>529519.0</td>\n",
       "      <td>2326.0</td>\n",
       "      <td>2543.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PFG</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>88511.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RRW</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>3045.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RSL</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>5623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>219.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>39014.0</td>\n",
       "      <td>5454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SUNBELT</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tonsa</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>48016.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Turn 14</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>343819.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wheel Pros</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>64315.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category    Warehouse Previous Date Latest Date  Same Price  Items Added  \\\n",
       "0               BROCK    2022-10-11  2022-10-12     11518.0          2.0   \n",
       "1               BURCO    2023-01-05  2023-01-06      4314.0          NaN   \n",
       "2              DORMAN    2023-01-04  2023-01-05     81753.0          6.0   \n",
       "3            KEYSTONE    2023-01-05  2023-01-06    145829.0        511.0   \n",
       "4                 LKQ    2023-01-04  2023-01-05     76447.0        218.0   \n",
       "5          MOTORSTATE    2023-01-04  2023-01-05    104484.0         28.0   \n",
       "6                 NPW    2023-01-04  2023-01-05    293532.0         41.0   \n",
       "7           OE WHEELS    2023-01-04  2023-01-05       766.0          3.0   \n",
       "8                  PA    2023-01-05  2023-01-06    529519.0       2326.0   \n",
       "9                 PFG    2023-01-05  2023-01-06     88511.0          4.0   \n",
       "10                RRW    2023-01-04  2023-01-06      3045.0        112.0   \n",
       "11                RSL    2023-01-04  2023-01-05      5623.0          NaN   \n",
       "12        SIMPLE TIRE    2023-01-04  2023-01-05       219.0        181.0   \n",
       "13            SUNBELT    2022-12-07  2022-12-08      1580.0          NaN   \n",
       "14              Tonsa    2023-01-04  2023-01-05     48016.0        316.0   \n",
       "15            Turn 14    2023-01-04  2023-01-06    343819.0          4.0   \n",
       "16         Wheel Pros    2023-01-04  2023-01-05     64315.0          NaN   \n",
       "\n",
       "Category  Items Removed  Price Decreased  Price Increased  \n",
       "0                   NaN              NaN              NaN  \n",
       "1                   NaN              NaN              NaN  \n",
       "2                   NaN              NaN              NaN  \n",
       "3                 309.0              4.0            376.0  \n",
       "4                 190.0              NaN              NaN  \n",
       "5                   7.0             35.0            403.0  \n",
       "6                 121.0              NaN              NaN  \n",
       "7                   NaN              NaN              NaN  \n",
       "8                2543.0           1260.0            662.0  \n",
       "9                  11.0              NaN              NaN  \n",
       "10                  NaN              1.0             53.0  \n",
       "11                  NaN              NaN              NaN  \n",
       "12                203.0          39014.0           5454.0  \n",
       "13                  NaN              NaN              NaN  \n",
       "14                178.0              1.0              4.0  \n",
       "15                369.0              NaN              2.0  \n",
       "16                  NaN              NaN              NaN  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pivot table of the 'Count' column of the r dataframe, with the rows being 'Warehouse', 'Previous Date', and 'Latest Date', \n",
    "# and the columns being 'Category'. Then reset the index of the resulting dataframe.\n",
    "summary = r.pivot_table('Count', ['Warehouse', 'Previous Date', 'Latest Date'], 'Category').reset_index()\n",
    "\n",
    "# select only the desired columns of the summary dataframe\n",
    "summary = summary[[\"Warehouse\", \"Previous Date\", \"Latest Date\", \"Same Price\",\n",
    "                   \"Items Added\", \"Items Removed\", \"Price Decreased\", \"Price Increased\"]]\n",
    "\n",
    "# create the filename for the summary file based on the current date, in the format \"Summary_YYYYMMDD.xlsx\"\n",
    "filename = today.strftime(\"Summary_%Y%m%d.xlsx\")\n",
    "\n",
    "# create the file path for saving the summary file on the local machine\n",
    "path = summaries_update + '\\\\' + filename\n",
    "\n",
    "# save the summary dataframe to an excel file at the specified file path\n",
    "summary.to_excel(path, index=False)\n",
    "\n",
    "# display the summary dataframe\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "67ad6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_thresh = {\n",
    "#     \"BROCK\": 6931,\n",
    "#     \"BURCO\" :4041,\n",
    "#     \"DORMAN\": 0,\n",
    "#     \"JANTE\" :470,\n",
    "#     \"KEYSTONE\":8149,\n",
    "#     \"LKQ\"       :14044,\n",
    "#     \"MOTORSTATE\" :8704,\n",
    "#     \"NPW\":364396,\n",
    "#     \"OE WHEELS\" :0,\n",
    "#     \"PA\":30918,\n",
    "#     \"PFG\"   :48180,\n",
    "#     \"RRW\" :286,\n",
    "#     \"RSL\":15,\n",
    "#     \"Turn 14\":100,\n",
    "#     \"SIMPLE TIRE\" :42518,\n",
    "#     \"SUNBELT\":867,\n",
    "#     \"TONSA\": 0,\n",
    "#     \"Wheel Pros\":1,\n",
    "#     \"Tonsa\":595,\n",
    "# }\n",
    "\n",
    "# items_thresh = {\n",
    "#     \"BROCK\": 100,\n",
    "#     \"BURCO\" :100,\n",
    "#     \"DORMAN\": 40,\n",
    "#     \"JANTE\" :50,\n",
    "#     \"KEYSTONE\":500,\n",
    "#     \"LKQ\"       :500,\n",
    "#     \"MOTORSTATE\" :200,\n",
    "#     \"NPW\":500,\n",
    "#     \"OE WHEELS\" :200,\n",
    "#     \"Turn 14\":100,\n",
    "#     \"PA\":200,\n",
    "#     \"PFG\"   :50,\n",
    "#     \"RRW\" :10,\n",
    "#     \"RSL\":100,\n",
    "#     \"SIMPLE TIRE\" :500,\n",
    "#     \"SUNBELT\":200,\n",
    "#     \"Wheel Pros\":1,\n",
    "#     \"Tonsa\":200,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1889154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary['thresh_price'] = summary['Warehouse'].map(items_thresh)\n",
    "# summary['thresh_items'] = summary['Warehouse'].map(items_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "bcde0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2c9ecc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 1, 7)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "8bcf0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of \"Yes\" or nan values based on the comparison of the element in the \"Latest Date\" column \n",
    "# with the current and yesterday dates\n",
    "recent_file = [\"Yes\" if (i == current_date or i == yesterday_date) else np.nan for i in summary[\"Latest Date\"]]\n",
    "\n",
    "# insert the list as a new column called \"Recent file on CS\" in the summary dataframe\n",
    "summary.insert(3, \"Recent file on CS\", recent_file)\n",
    "\n",
    "# sort the summary dataframe by the \"Latest Date\" column in ascending order\n",
    "summary = summary.sort_values(by = \"Latest Date\", ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ce705242",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['Same Price'] = summary['Same Price'].astype(int)\n",
    "summary['Items Added'] = summary['Items Added'].astype(int)\n",
    "summary['Items Removed'] = summary['Items Removed'].astype(int)\n",
    "summary['Price Decreased'] = summary['Price Decreased'].astype(int)\n",
    "summary['Price Increased'] = summary['Price Increased'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "eb3e1fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Category</th>\n",
       "      <th>Warehouse</th>\n",
       "      <th>Previous Date</th>\n",
       "      <th>Latest Date</th>\n",
       "      <th>Recent file on CS</th>\n",
       "      <th>Same Price</th>\n",
       "      <th>Items Added</th>\n",
       "      <th>Items Removed</th>\n",
       "      <th>Price Decreased</th>\n",
       "      <th>Price Increased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROCK</td>\n",
       "      <td>10-11-2022</td>\n",
       "      <td>10-12-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11518</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SUNBELT</td>\n",
       "      <td>12-07-2022</td>\n",
       "      <td>12-08-2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tonsa</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48016</td>\n",
       "      <td>316</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SIMPLE TIRE</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>181</td>\n",
       "      <td>203</td>\n",
       "      <td>39014</td>\n",
       "      <td>5454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RSL</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OE WHEELS</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>766</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wheel Pros</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MOTORSTATE</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104484</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LKQ</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76447</td>\n",
       "      <td>218</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DORMAN</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81753</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NPW</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293532</td>\n",
       "      <td>41</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Turn 14</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-06-2023</td>\n",
       "      <td>Yes</td>\n",
       "      <td>343819</td>\n",
       "      <td>4</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PFG</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>01-06-2023</td>\n",
       "      <td>Yes</td>\n",
       "      <td>88511</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RRW</td>\n",
       "      <td>01-04-2023</td>\n",
       "      <td>01-06-2023</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3045</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KEYSTONE</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>01-06-2023</td>\n",
       "      <td>Yes</td>\n",
       "      <td>145829</td>\n",
       "      <td>511</td>\n",
       "      <td>309</td>\n",
       "      <td>4</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURCO</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>01-06-2023</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PA</td>\n",
       "      <td>01-05-2023</td>\n",
       "      <td>01-06-2023</td>\n",
       "      <td>Yes</td>\n",
       "      <td>529519</td>\n",
       "      <td>2326</td>\n",
       "      <td>2543</td>\n",
       "      <td>1260</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Category    Warehouse Previous Date Latest Date Recent file on CS  Same Price  \\\n",
       "0               BROCK    10-11-2022  10-12-2022               NaN       11518   \n",
       "13            SUNBELT    12-07-2022  12-08-2022               NaN        1580   \n",
       "14              Tonsa    01-04-2023  01-05-2023               NaN       48016   \n",
       "12        SIMPLE TIRE    01-04-2023  01-05-2023               NaN         219   \n",
       "11                RSL    01-04-2023  01-05-2023               NaN        5623   \n",
       "7           OE WHEELS    01-04-2023  01-05-2023               NaN         766   \n",
       "16         Wheel Pros    01-04-2023  01-05-2023               NaN       64315   \n",
       "5          MOTORSTATE    01-04-2023  01-05-2023               NaN      104484   \n",
       "4                 LKQ    01-04-2023  01-05-2023               NaN       76447   \n",
       "2              DORMAN    01-04-2023  01-05-2023               NaN       81753   \n",
       "6                 NPW    01-04-2023  01-05-2023               NaN      293532   \n",
       "15            Turn 14    01-04-2023  01-06-2023               Yes      343819   \n",
       "9                 PFG    01-05-2023  01-06-2023               Yes       88511   \n",
       "10                RRW    01-04-2023  01-06-2023               Yes        3045   \n",
       "3            KEYSTONE    01-05-2023  01-06-2023               Yes      145829   \n",
       "1               BURCO    01-05-2023  01-06-2023               Yes        4314   \n",
       "8                  PA    01-05-2023  01-06-2023               Yes      529519   \n",
       "\n",
       "Category  Items Added  Items Removed  Price Decreased  Price Increased  \n",
       "0                   2              0                0                0  \n",
       "13                  0              0                0                0  \n",
       "14                316            178                1                4  \n",
       "12                181            203            39014             5454  \n",
       "11                  0              0                0                0  \n",
       "7                   3              0                0                0  \n",
       "16                  0              0                0                0  \n",
       "5                  28              7               35              403  \n",
       "4                 218            190                0                0  \n",
       "2                   6              0                0                0  \n",
       "6                  41            121                0                0  \n",
       "15                  4            369                0                2  \n",
       "9                   4             11                0                0  \n",
       "10                112              0                1               53  \n",
       "3                 511            309                4              376  \n",
       "1                   0              0                0                0  \n",
       "8                2326           2543             1260              662  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the format of the dates in the dataframe as 'DD-MM-YYYY'\n",
    "date_format = '%d-%m-%Y'\n",
    "\n",
    "# convert the \"Previous Date\" column of the summary dataframe to datetime type, then format the dates as \n",
    "# strings with the defined format and store the result back in the \"Previous Date\" column\n",
    "summary[\"Previous Date\"] = pd.to_datetime(summary[\"Previous Date\"]).dt.strftime(date_format)\n",
    "\n",
    "# convert the \"Latest Date\" column of the summary dataframe to datetime type, then format the dates as \n",
    "# strings with the defined format and store the result back in the \"Latest Date\" column\n",
    "summary[\"Latest Date\"] = pd.to_datetime(summary[\"Latest Date\"]).dt.strftime(date_format)\n",
    "\n",
    "# display the summary dataframe\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ceb7d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataframe_image module\n",
    "import dataframe_image as dfi\n",
    "\n",
    "# style the summary dataframe by adding a red gradient background to the specified columns, \n",
    "# formatting cells with no data as \"No Recent File\" and highlighting cells with null values as yellow\n",
    "summary_styled = summary.style.background_gradient(subset=['Price Increased', 'Items Added', 'Items Removed', 'Price Decreased'], cmap=\"Reds\", vmin = 1499, vmax = 1500).format(na_rep=\"No Recent File\").highlight_null(null_color=\"yellow\")\n",
    "\n",
    "# export the styled dataframe as an image and save it as \"df_styled.png\"\n",
    "dfi.export(summary_styled, 'df_styled.png', dpi = 1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fddcaf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f6339_row0_col3, #T_f6339_row1_col3, #T_f6339_row2_col3, #T_f6339_row3_col3, #T_f6339_row4_col3, #T_f6339_row5_col3, #T_f6339_row6_col3, #T_f6339_row7_col3, #T_f6339_row8_col3, #T_f6339_row9_col3, #T_f6339_row10_col3 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_f6339_row0_col5, #T_f6339_row0_col6, #T_f6339_row0_col7, #T_f6339_row0_col8, #T_f6339_row1_col5, #T_f6339_row1_col6, #T_f6339_row1_col7, #T_f6339_row1_col8, #T_f6339_row2_col5, #T_f6339_row2_col6, #T_f6339_row2_col7, #T_f6339_row2_col8, #T_f6339_row3_col5, #T_f6339_row3_col6, #T_f6339_row4_col5, #T_f6339_row4_col6, #T_f6339_row4_col7, #T_f6339_row4_col8, #T_f6339_row5_col5, #T_f6339_row5_col6, #T_f6339_row5_col7, #T_f6339_row5_col8, #T_f6339_row6_col5, #T_f6339_row6_col6, #T_f6339_row6_col7, #T_f6339_row6_col8, #T_f6339_row7_col5, #T_f6339_row7_col6, #T_f6339_row7_col7, #T_f6339_row7_col8, #T_f6339_row8_col5, #T_f6339_row8_col6, #T_f6339_row8_col7, #T_f6339_row8_col8, #T_f6339_row9_col5, #T_f6339_row9_col6, #T_f6339_row9_col7, #T_f6339_row9_col8, #T_f6339_row10_col5, #T_f6339_row10_col6, #T_f6339_row10_col7, #T_f6339_row10_col8, #T_f6339_row11_col5, #T_f6339_row11_col6, #T_f6339_row11_col7, #T_f6339_row11_col8, #T_f6339_row12_col5, #T_f6339_row12_col6, #T_f6339_row12_col7, #T_f6339_row12_col8, #T_f6339_row13_col5, #T_f6339_row13_col6, #T_f6339_row13_col7, #T_f6339_row13_col8, #T_f6339_row14_col5, #T_f6339_row14_col6, #T_f6339_row14_col7, #T_f6339_row14_col8, #T_f6339_row15_col5, #T_f6339_row15_col6, #T_f6339_row15_col7, #T_f6339_row15_col8, #T_f6339_row16_col7, #T_f6339_row16_col8 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f6339_row3_col7, #T_f6339_row3_col8, #T_f6339_row16_col5, #T_f6339_row16_col6 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f6339\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Category</th>\n",
       "      <th id=\"T_f6339_level0_col0\" class=\"col_heading level0 col0\" >Warehouse</th>\n",
       "      <th id=\"T_f6339_level0_col1\" class=\"col_heading level0 col1\" >Previous Date</th>\n",
       "      <th id=\"T_f6339_level0_col2\" class=\"col_heading level0 col2\" >Latest Date</th>\n",
       "      <th id=\"T_f6339_level0_col3\" class=\"col_heading level0 col3\" >Recent file on CS</th>\n",
       "      <th id=\"T_f6339_level0_col4\" class=\"col_heading level0 col4\" >Same Price</th>\n",
       "      <th id=\"T_f6339_level0_col5\" class=\"col_heading level0 col5\" >Items Added</th>\n",
       "      <th id=\"T_f6339_level0_col6\" class=\"col_heading level0 col6\" >Items Removed</th>\n",
       "      <th id=\"T_f6339_level0_col7\" class=\"col_heading level0 col7\" >Price Decreased</th>\n",
       "      <th id=\"T_f6339_level0_col8\" class=\"col_heading level0 col8\" >Price Increased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f6339_row0_col0\" class=\"data row0 col0\" >BROCK</td>\n",
       "      <td id=\"T_f6339_row0_col1\" class=\"data row0 col1\" >10-11-2022</td>\n",
       "      <td id=\"T_f6339_row0_col2\" class=\"data row0 col2\" >10-12-2022</td>\n",
       "      <td id=\"T_f6339_row0_col3\" class=\"data row0 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row0_col4\" class=\"data row0 col4\" >11518</td>\n",
       "      <td id=\"T_f6339_row0_col5\" class=\"data row0 col5\" >2</td>\n",
       "      <td id=\"T_f6339_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row1\" class=\"row_heading level0 row1\" >13</th>\n",
       "      <td id=\"T_f6339_row1_col0\" class=\"data row1 col0\" >SUNBELT</td>\n",
       "      <td id=\"T_f6339_row1_col1\" class=\"data row1 col1\" >12-07-2022</td>\n",
       "      <td id=\"T_f6339_row1_col2\" class=\"data row1 col2\" >12-08-2022</td>\n",
       "      <td id=\"T_f6339_row1_col3\" class=\"data row1 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row1_col4\" class=\"data row1 col4\" >1580</td>\n",
       "      <td id=\"T_f6339_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_f6339_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row1_col7\" class=\"data row1 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row1_col8\" class=\"data row1 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row2\" class=\"row_heading level0 row2\" >14</th>\n",
       "      <td id=\"T_f6339_row2_col0\" class=\"data row2 col0\" >Tonsa</td>\n",
       "      <td id=\"T_f6339_row2_col1\" class=\"data row2 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row2_col2\" class=\"data row2 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row2_col3\" class=\"data row2 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row2_col4\" class=\"data row2 col4\" >48016</td>\n",
       "      <td id=\"T_f6339_row2_col5\" class=\"data row2 col5\" >316</td>\n",
       "      <td id=\"T_f6339_row2_col6\" class=\"data row2 col6\" >178</td>\n",
       "      <td id=\"T_f6339_row2_col7\" class=\"data row2 col7\" >1</td>\n",
       "      <td id=\"T_f6339_row2_col8\" class=\"data row2 col8\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row3\" class=\"row_heading level0 row3\" >12</th>\n",
       "      <td id=\"T_f6339_row3_col0\" class=\"data row3 col0\" >SIMPLE TIRE</td>\n",
       "      <td id=\"T_f6339_row3_col1\" class=\"data row3 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row3_col2\" class=\"data row3 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row3_col3\" class=\"data row3 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row3_col4\" class=\"data row3 col4\" >219</td>\n",
       "      <td id=\"T_f6339_row3_col5\" class=\"data row3 col5\" >181</td>\n",
       "      <td id=\"T_f6339_row3_col6\" class=\"data row3 col6\" >203</td>\n",
       "      <td id=\"T_f6339_row3_col7\" class=\"data row3 col7\" >39014</td>\n",
       "      <td id=\"T_f6339_row3_col8\" class=\"data row3 col8\" >5454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row4\" class=\"row_heading level0 row4\" >11</th>\n",
       "      <td id=\"T_f6339_row4_col0\" class=\"data row4 col0\" >RSL</td>\n",
       "      <td id=\"T_f6339_row4_col1\" class=\"data row4 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row4_col2\" class=\"data row4 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row4_col3\" class=\"data row4 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row4_col4\" class=\"data row4 col4\" >5623</td>\n",
       "      <td id=\"T_f6339_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_f6339_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row5\" class=\"row_heading level0 row5\" >7</th>\n",
       "      <td id=\"T_f6339_row5_col0\" class=\"data row5 col0\" >OE WHEELS</td>\n",
       "      <td id=\"T_f6339_row5_col1\" class=\"data row5 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row5_col2\" class=\"data row5 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row5_col3\" class=\"data row5 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row5_col4\" class=\"data row5 col4\" >766</td>\n",
       "      <td id=\"T_f6339_row5_col5\" class=\"data row5 col5\" >3</td>\n",
       "      <td id=\"T_f6339_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row6\" class=\"row_heading level0 row6\" >16</th>\n",
       "      <td id=\"T_f6339_row6_col0\" class=\"data row6 col0\" >Wheel Pros</td>\n",
       "      <td id=\"T_f6339_row6_col1\" class=\"data row6 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row6_col2\" class=\"data row6 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row6_col3\" class=\"data row6 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row6_col4\" class=\"data row6 col4\" >64315</td>\n",
       "      <td id=\"T_f6339_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_f6339_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row7\" class=\"row_heading level0 row7\" >5</th>\n",
       "      <td id=\"T_f6339_row7_col0\" class=\"data row7 col0\" >MOTORSTATE</td>\n",
       "      <td id=\"T_f6339_row7_col1\" class=\"data row7 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row7_col2\" class=\"data row7 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row7_col3\" class=\"data row7 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row7_col4\" class=\"data row7 col4\" >104484</td>\n",
       "      <td id=\"T_f6339_row7_col5\" class=\"data row7 col5\" >28</td>\n",
       "      <td id=\"T_f6339_row7_col6\" class=\"data row7 col6\" >7</td>\n",
       "      <td id=\"T_f6339_row7_col7\" class=\"data row7 col7\" >35</td>\n",
       "      <td id=\"T_f6339_row7_col8\" class=\"data row7 col8\" >403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row8\" class=\"row_heading level0 row8\" >4</th>\n",
       "      <td id=\"T_f6339_row8_col0\" class=\"data row8 col0\" >LKQ</td>\n",
       "      <td id=\"T_f6339_row8_col1\" class=\"data row8 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row8_col2\" class=\"data row8 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row8_col3\" class=\"data row8 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row8_col4\" class=\"data row8 col4\" >76447</td>\n",
       "      <td id=\"T_f6339_row8_col5\" class=\"data row8 col5\" >218</td>\n",
       "      <td id=\"T_f6339_row8_col6\" class=\"data row8 col6\" >190</td>\n",
       "      <td id=\"T_f6339_row8_col7\" class=\"data row8 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row8_col8\" class=\"data row8 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row9\" class=\"row_heading level0 row9\" >2</th>\n",
       "      <td id=\"T_f6339_row9_col0\" class=\"data row9 col0\" >DORMAN</td>\n",
       "      <td id=\"T_f6339_row9_col1\" class=\"data row9 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row9_col2\" class=\"data row9 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row9_col3\" class=\"data row9 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row9_col4\" class=\"data row9 col4\" >81753</td>\n",
       "      <td id=\"T_f6339_row9_col5\" class=\"data row9 col5\" >6</td>\n",
       "      <td id=\"T_f6339_row9_col6\" class=\"data row9 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row9_col7\" class=\"data row9 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row9_col8\" class=\"data row9 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row10\" class=\"row_heading level0 row10\" >6</th>\n",
       "      <td id=\"T_f6339_row10_col0\" class=\"data row10 col0\" >NPW</td>\n",
       "      <td id=\"T_f6339_row10_col1\" class=\"data row10 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row10_col2\" class=\"data row10 col2\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row10_col3\" class=\"data row10 col3\" >No Recent File</td>\n",
       "      <td id=\"T_f6339_row10_col4\" class=\"data row10 col4\" >293532</td>\n",
       "      <td id=\"T_f6339_row10_col5\" class=\"data row10 col5\" >41</td>\n",
       "      <td id=\"T_f6339_row10_col6\" class=\"data row10 col6\" >121</td>\n",
       "      <td id=\"T_f6339_row10_col7\" class=\"data row10 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row10_col8\" class=\"data row10 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row11\" class=\"row_heading level0 row11\" >15</th>\n",
       "      <td id=\"T_f6339_row11_col0\" class=\"data row11 col0\" >Turn 14</td>\n",
       "      <td id=\"T_f6339_row11_col1\" class=\"data row11 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row11_col2\" class=\"data row11 col2\" >01-06-2023</td>\n",
       "      <td id=\"T_f6339_row11_col3\" class=\"data row11 col3\" >Yes</td>\n",
       "      <td id=\"T_f6339_row11_col4\" class=\"data row11 col4\" >343819</td>\n",
       "      <td id=\"T_f6339_row11_col5\" class=\"data row11 col5\" >4</td>\n",
       "      <td id=\"T_f6339_row11_col6\" class=\"data row11 col6\" >369</td>\n",
       "      <td id=\"T_f6339_row11_col7\" class=\"data row11 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row11_col8\" class=\"data row11 col8\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row12\" class=\"row_heading level0 row12\" >9</th>\n",
       "      <td id=\"T_f6339_row12_col0\" class=\"data row12 col0\" >PFG</td>\n",
       "      <td id=\"T_f6339_row12_col1\" class=\"data row12 col1\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row12_col2\" class=\"data row12 col2\" >01-06-2023</td>\n",
       "      <td id=\"T_f6339_row12_col3\" class=\"data row12 col3\" >Yes</td>\n",
       "      <td id=\"T_f6339_row12_col4\" class=\"data row12 col4\" >88511</td>\n",
       "      <td id=\"T_f6339_row12_col5\" class=\"data row12 col5\" >4</td>\n",
       "      <td id=\"T_f6339_row12_col6\" class=\"data row12 col6\" >11</td>\n",
       "      <td id=\"T_f6339_row12_col7\" class=\"data row12 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row12_col8\" class=\"data row12 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row13\" class=\"row_heading level0 row13\" >10</th>\n",
       "      <td id=\"T_f6339_row13_col0\" class=\"data row13 col0\" >RRW</td>\n",
       "      <td id=\"T_f6339_row13_col1\" class=\"data row13 col1\" >01-04-2023</td>\n",
       "      <td id=\"T_f6339_row13_col2\" class=\"data row13 col2\" >01-06-2023</td>\n",
       "      <td id=\"T_f6339_row13_col3\" class=\"data row13 col3\" >Yes</td>\n",
       "      <td id=\"T_f6339_row13_col4\" class=\"data row13 col4\" >3045</td>\n",
       "      <td id=\"T_f6339_row13_col5\" class=\"data row13 col5\" >112</td>\n",
       "      <td id=\"T_f6339_row13_col6\" class=\"data row13 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row13_col7\" class=\"data row13 col7\" >1</td>\n",
       "      <td id=\"T_f6339_row13_col8\" class=\"data row13 col8\" >53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row14\" class=\"row_heading level0 row14\" >3</th>\n",
       "      <td id=\"T_f6339_row14_col0\" class=\"data row14 col0\" >KEYSTONE</td>\n",
       "      <td id=\"T_f6339_row14_col1\" class=\"data row14 col1\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row14_col2\" class=\"data row14 col2\" >01-06-2023</td>\n",
       "      <td id=\"T_f6339_row14_col3\" class=\"data row14 col3\" >Yes</td>\n",
       "      <td id=\"T_f6339_row14_col4\" class=\"data row14 col4\" >145829</td>\n",
       "      <td id=\"T_f6339_row14_col5\" class=\"data row14 col5\" >511</td>\n",
       "      <td id=\"T_f6339_row14_col6\" class=\"data row14 col6\" >309</td>\n",
       "      <td id=\"T_f6339_row14_col7\" class=\"data row14 col7\" >4</td>\n",
       "      <td id=\"T_f6339_row14_col8\" class=\"data row14 col8\" >376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row15\" class=\"row_heading level0 row15\" >1</th>\n",
       "      <td id=\"T_f6339_row15_col0\" class=\"data row15 col0\" >BURCO</td>\n",
       "      <td id=\"T_f6339_row15_col1\" class=\"data row15 col1\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row15_col2\" class=\"data row15 col2\" >01-06-2023</td>\n",
       "      <td id=\"T_f6339_row15_col3\" class=\"data row15 col3\" >Yes</td>\n",
       "      <td id=\"T_f6339_row15_col4\" class=\"data row15 col4\" >4314</td>\n",
       "      <td id=\"T_f6339_row15_col5\" class=\"data row15 col5\" >0</td>\n",
       "      <td id=\"T_f6339_row15_col6\" class=\"data row15 col6\" >0</td>\n",
       "      <td id=\"T_f6339_row15_col7\" class=\"data row15 col7\" >0</td>\n",
       "      <td id=\"T_f6339_row15_col8\" class=\"data row15 col8\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f6339_level0_row16\" class=\"row_heading level0 row16\" >8</th>\n",
       "      <td id=\"T_f6339_row16_col0\" class=\"data row16 col0\" >PA</td>\n",
       "      <td id=\"T_f6339_row16_col1\" class=\"data row16 col1\" >01-05-2023</td>\n",
       "      <td id=\"T_f6339_row16_col2\" class=\"data row16 col2\" >01-06-2023</td>\n",
       "      <td id=\"T_f6339_row16_col3\" class=\"data row16 col3\" >Yes</td>\n",
       "      <td id=\"T_f6339_row16_col4\" class=\"data row16 col4\" >529519</td>\n",
       "      <td id=\"T_f6339_row16_col5\" class=\"data row16 col5\" >2326</td>\n",
       "      <td id=\"T_f6339_row16_col6\" class=\"data row16 col6\" >2543</td>\n",
       "      <td id=\"T_f6339_row16_col7\" class=\"data row16 col7\" >1260</td>\n",
       "      <td id=\"T_f6339_row16_col8\" class=\"data row16 col8\" >662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2040a3a49d0>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_styled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b044fc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fahad Razzaq\\anaconda3\\lib\\site-packages\\slack_sdk\\web\\client.py:3032: UserWarning: Although the channels parameter is still supported for smooth migration from legacy files.upload, we recommend using the new channel parameter with a single str value instead for more clarity.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<slack_sdk.web.slack_response.SlackResponse at 0x2045a2cd3a0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the slack_sdk module\n",
    "import slack_sdk\n",
    "\n",
    "# store the channel id for the slack channel where the message and file will be sent\n",
    "cid = 'C03BTASE476'\n",
    "\n",
    "# create a client for the slack API using the WebClient class and the specified token\n",
    "c = slack_sdk.WebClient(token='xoxb-156915382752-4437979958069-2XlrUKvulSUOltDeqdlHrqjA')\n",
    "\n",
    "# create the text for the message to be sent, using the current date\n",
    "text = 'Inventory Comparison ' + current_date.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "# send a message to the specified slack channel with the created text\n",
    "c.chat_postMessage(channel=cid, text=text)\n",
    "\n",
    "# send the image file \"df_styled.png\" to the specified slack channel\n",
    "c.files_upload_v2(file='df_styled.png', channels='C03BTASE476')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6446b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddaf44d",
   "metadata": {},
   "source": [
    "<center><h2> --- THE END ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
